{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768860a4",
   "metadata": {},
   "source": [
    "1. Downloading the model \n",
    "2. Loading dataset\n",
    "3. Splitting dataset \n",
    "4. Embeddings - Semantic Representations \n",
    "5. Model Loading \n",
    "6. Train / Val\n",
    "7. Prediction pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487ae4c",
   "metadata": {},
   "source": [
    "Image credit: https://jalammar.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ca602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a959d8b4",
   "metadata": {},
   "source": [
    "In last session, we learned about the traditional NLP techniques to build a Sentiment classifier\n",
    "\n",
    "In this session, we will get familiarised with more advanced techniques, especially LLMs, and use it to build the same classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2024918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90da832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  label\n",
       "0  Wow... Loved this place.      1\n",
       "1        Crust is not good.      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets start with importing the same dataset we used in the previous session\n",
    "# this is a dataset of yelp reviews, with each review labelled as positive or negative\n",
    "# the dataset is available at data/yelp_reviews.txt\n",
    "# the file is a tab-separated file with two columns: text and label\n",
    "\n",
    "df = pd.read_csv(f\"data/yelp_reviews.txt\", sep=\"\\t\", header=None, names=[\"text\", \"label\"])\n",
    "print(df.shape)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59de8be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashishu007/Documents/side-projects/nlp-intro/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# lets define some helper functions to pre-process the text and extract features from them using traditional NLP techniques\n",
    "# same as from the previous session\n",
    "# just to recap, what we did and how the processing/feature extraction looks like\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Processes the input text by tokenizing, stemming, and removing stop words.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def identity_tokenizer(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=identity_tokenizer, lowercase=False)\n",
    "df[\"tokens\"] = df[\"text\"].apply(process_text)\n",
    "count_vectorizer.fit(df[\"tokens\"])\n",
    "\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Vectorizes the input tokens using the pre-trained CountVectorizer.\n",
    "    \"\"\"\n",
    "    tokens = process_text(text)\n",
    "    vectorized_text = count_vectorizer.transform([tokens])\n",
    "    vectorized_df = pd.DataFrame(\n",
    "        vectorized_text.todense(), columns=count_vectorizer.get_feature_names_out()\n",
    "    )\n",
    "    return vectorized_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf5908b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"tokens\"]\n",
    "# extract_features(\"This is a great product, I love it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45975269",
   "metadata": {},
   "source": [
    "<!-- ![alt text](images/traditional-sentiment-classifier.png) -->\n",
    "\n",
    "<img src=\"images/traditional-sentiments-classifier.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d4c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how the preprcessing and feature extraction looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a45172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>[wow, love, thi, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>[crust, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  label                   tokens\n",
       "0  Wow... Loved this place.      1  [wow, love, thi, place]\n",
       "1        Crust is not good.      0            [crust, good]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokens\"] = df.text.apply(process_text)\n",
    "print(df.shape)\n",
    "df.head(2)\n",
    "# crust not good - missed context by ignoring stop words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2505c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"The city is located on the bank of the river\"\n",
    "text2 = \"Let's go to the bank and deposit some money\"\n",
    "vectorized_df1 = extract_features(text1)\n",
    "vectorized_df2 = extract_features(text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050d11ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>accid</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accomod</th>\n",
       "      <th>accordingli</th>\n",
       "      <th>account</th>\n",
       "      <th>ach</th>\n",
       "      <th>acknowledg</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellowtail</th>\n",
       "      <th>yelper</th>\n",
       "      <th>yet</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummi</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abov  absolut  absolutley  accid  accommod  accomod  accordingli  account  \\\n",
       "0     0        0           0      0         0        0            0        0   \n",
       "\n",
       "   ach  acknowledg  ...  year  yellow  yellowtail  yelper  yet  yucki  yukon  \\\n",
       "0    0           0  ...     0       0           0       0    0      0      0   \n",
       "\n",
       "   yum  yummi  zero  \n",
       "0    0      0     0  \n",
       "\n",
       "[1 rows x 1553 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c28e56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>accid</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accomod</th>\n",
       "      <th>accordingli</th>\n",
       "      <th>account</th>\n",
       "      <th>ach</th>\n",
       "      <th>acknowledg</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellowtail</th>\n",
       "      <th>yelper</th>\n",
       "      <th>yet</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummi</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abov  absolut  absolutley  accid  accommod  accomod  accordingli  account  \\\n",
       "0     0        0           0      0         0        0            0        0   \n",
       "\n",
       "   ach  acknowledg  ...  year  yellow  yellowtail  yelper  yet  yucki  yukon  \\\n",
       "0    0           0  ...     0       0           0       0    0      0      0   \n",
       "\n",
       "   yum  yummi  zero  \n",
       "0    0      0     0  \n",
       "\n",
       "[1 rows x 1553 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92fbe152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df2[\"bank\"].values, vectorized_df2[\"bank\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b38fc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing context by ignoring stop words\n",
    "# we can see that the word \"bank\" is present in both sentences, but the context\n",
    "# is different. In the first sentence, \"bank\" refers to the side of a river\n",
    "# while in the second sentence, it refers to a financial institution.\n",
    "# this is a limitation of traditional NLP techniques, as they do not take into account the context of the words\n",
    "# in the sentence. This is where BERT comes in, as it is able to take into account the context of the words in the sentence\n",
    "# and provide a more accurate representation of the text.\n",
    "# BERT is a transformer-based model that uses attention mechanisms to understand the context of the text.\n",
    "# It is pre-trained on a large corpus of text and can be fine-tuned for specific tasks such as sentiment analysis, text classification, etc.\n",
    "# In the next section, we will see how to use BERT for text classification tasks.\n",
    "# We will use the Hugging Face Transformers library to load a pre-trained BERT model and fine-tune it on our dataset.\n",
    "# The Hugging Face Transformers library provides a simple and easy-to-use interface for working with BERT and other transformer-based models.\n",
    "# It also provides a wide range of pre-trained models that can be used for various NLP tasks.\n",
    "# We will use the BERT model for text classification tasks, specifically for sentiment analysis.\n",
    "# We will fine-tune the BERT model on our dataset and evaluate its performance on the test set.\n",
    "# The BERT model will be able to take into account the context of the text and provide a more accurate representation of the text.\n",
    "# This will help us to improve the performance of our text classification tasks and provide better results.\n",
    "# Let's see how to use BERT for text classification tasks using the Hugging Face Transformers library.\n",
    "# We will use the BERT model for sentiment analysis and fine-tune it on our dataset.\n",
    "# We will also evaluate its performance on the test set and compare it with the traditional NLP techniques we used earlier.\n",
    "# This will help us to understand the advantages of using BERT for text classification tasks and how it can improve the performance of our models\n",
    "# compared to traditional NLP techniques.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a3d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6734f921",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42fcc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems of basic methods\n",
    "\n",
    "# ignore context etc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565a9de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19180ad1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42976366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashishu007/Documents/side-projects/nlp-intro/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ee87408",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56da3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "language_model = transformers.AutoModel.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70522ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51b3db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the embs of same words in two different contexts\n",
    "text1 = \"The city is located on the bank of the river\"\n",
    "text2 = \"Let's go to the bank and deposit some money\"\n",
    "inputs1 = tokenizer(text1, return_tensors=\"pt\")\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\")\n",
    "# print(inputs1)\n",
    "# tokenizer.decode(inputs1[\"input_ids\"][0][-5]), tokenizer.decode(inputs2[\"input_ids\"][0][-6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71bcfc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    outputs1 = language_model(**inputs1)\n",
    "    outputs2 = language_model(**inputs2)\n",
    "emb1 = outputs1.last_hidden_state[0, -5, :]\n",
    "emb2 = outputs2.last_hidden_state[0, -6, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed5c3243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([-7.6490e-01, -6.1477e-03, -1.7706e-03, -1.2309e-01,  9.9662e-02,\n",
      "         7.4598e-01,  4.8393e-01,  2.0661e+00,  2.6952e-01, -7.3961e-01,\n",
      "         9.7105e-01,  5.0583e-02, -1.7607e-02,  7.8000e-01, -1.3304e+00,\n",
      "         6.2705e-01,  2.7906e-01, -6.0350e-02,  9.5401e-01,  3.9542e-01,\n",
      "        -3.1358e-01,  5.0624e-01,  2.9914e-01,  1.1412e+00, -5.0115e-01,\n",
      "         3.1991e-02,  9.1508e-02,  4.7217e-01,  3.9590e-01,  1.8770e-01,\n",
      "         1.0081e+00,  3.7353e-01,  3.3866e-01,  5.4936e-02, -5.4455e-01,\n",
      "        -5.2585e-01, -4.7111e-01, -5.9590e-01, -7.7133e-01, -1.6177e-02,\n",
      "        -9.0143e-01, -8.3997e-01, -2.2339e-01,  9.8848e-01,  1.6927e-01,\n",
      "        -5.9720e-02,  8.2857e-01, -3.5977e-01,  4.6731e-01,  9.1251e-01,\n",
      "         2.0006e-01,  1.7635e+00,  3.0672e-01, -4.0032e-01, -2.5774e-01,\n",
      "         4.8264e-01, -6.4338e-01, -7.1181e-01, -7.4939e-01, -5.2484e-01,\n",
      "         9.1113e-01,  8.0004e-02,  3.3433e-01, -5.2414e-02,  1.7914e-01,\n",
      "         2.6137e-01, -5.7129e-01, -3.0384e-01, -1.5808e-01,  9.7785e-02,\n",
      "         1.1122e-01,  4.4037e-01, -8.5639e-01, -1.4076e-01,  9.1285e-02,\n",
      "        -4.1665e-01, -2.2797e-01,  9.2799e-01,  2.3168e-01, -2.6324e-01,\n",
      "        -2.9441e-01, -6.7638e-01,  1.8113e-01,  7.9502e-01,  2.9719e-01,\n",
      "        -8.4007e-01,  6.6051e-01,  1.1374e-01, -7.5888e-01, -4.1929e-01,\n",
      "        -7.2226e-01, -4.7083e-01, -2.1060e-01, -4.2858e-01,  2.3341e-01,\n",
      "        -2.7716e-01, -1.1668e+00, -4.6261e-01,  2.9790e-01,  4.4812e-01,\n",
      "         1.1446e-01, -1.4231e+00,  9.5541e-01,  4.7277e-02, -6.7236e-01,\n",
      "        -3.8694e-01, -2.6269e-01, -5.0961e-01,  1.5622e-01,  3.6731e-01,\n",
      "        -3.6339e-01, -7.1495e-03,  7.0689e-01, -5.1622e-01, -9.4199e-01,\n",
      "         3.9676e-01, -2.1881e-01, -3.3697e-01, -1.1109e+00, -4.4432e-01,\n",
      "         4.3782e-01,  9.9917e-02, -3.0272e-01,  7.6025e-01,  2.5270e-02,\n",
      "         1.5325e-01,  1.7012e-01,  2.1038e-01, -1.4409e+00, -2.5762e-02,\n",
      "         1.1089e-01,  3.0663e-01,  2.5081e-01, -7.3566e-02,  2.3015e-01,\n",
      "         2.2980e-01, -2.4022e-01, -9.1105e-01, -3.7149e-01,  3.0368e-01,\n",
      "         7.5123e-02,  2.6783e-01,  3.1322e-01, -4.0763e-02,  6.3688e-01,\n",
      "         7.0090e-01, -2.9322e-02, -1.4823e+00, -7.5738e-01,  1.2645e-01,\n",
      "         2.8002e-01, -4.1018e-01, -6.7822e-01,  1.1168e-01, -1.5617e-04,\n",
      "         2.7199e-01, -6.8094e-02, -2.8468e-03,  2.1475e-01,  5.4097e-01,\n",
      "        -1.0096e-01,  1.5240e-01,  6.0707e-01, -2.1873e-01, -4.3753e-01,\n",
      "        -1.1792e+00,  3.2444e-01,  3.4418e-01, -4.8808e-01,  9.3231e-01,\n",
      "        -4.5250e-01, -1.2676e+00,  4.5921e-01, -3.1175e-01,  1.0971e+00,\n",
      "        -5.3085e-01, -5.2606e-01,  3.8872e-02, -7.4779e-01,  4.1332e-01,\n",
      "        -7.0666e-01,  8.2232e-01,  4.9271e-01,  8.7428e-01,  2.1872e-01,\n",
      "         1.4722e-02,  8.6512e-01, -3.5140e-01,  8.0682e-01, -4.2315e-02,\n",
      "         2.2269e-01, -7.7272e-01, -1.1768e+00, -6.0973e-02, -1.2747e-01,\n",
      "        -1.4095e+00, -7.3936e-01, -7.0067e-01, -3.9476e-01,  2.0682e-02,\n",
      "        -2.1223e-01, -7.8968e-01,  7.4714e-01, -5.2701e-01,  3.2194e-01,\n",
      "         8.3570e-01,  2.8154e-01, -3.6329e-01,  2.4833e-01,  3.7742e-01,\n",
      "        -2.2453e-01,  5.2846e-01,  3.4959e-01, -1.5379e-01, -1.5284e-01,\n",
      "         2.8837e-01,  3.3930e-01, -3.8739e-01,  5.6872e-01, -5.0668e-01,\n",
      "         7.2347e-01,  4.9363e-01, -2.4118e-01, -1.2930e-01,  3.6172e-01,\n",
      "        -8.6901e-02,  2.6950e-01, -4.0318e-01,  3.8763e-01,  5.5425e-01,\n",
      "        -2.5094e-01,  1.4261e+00,  9.0356e-01, -1.4332e-01, -6.2310e-01,\n",
      "         1.9225e-01, -1.1741e+00,  8.0049e-01, -1.7832e-01,  7.1965e-02,\n",
      "         3.0407e-01,  8.7101e-01,  3.1706e-01, -6.6710e-01,  5.9381e-01,\n",
      "        -4.4158e-01,  2.6527e-01,  4.1599e-01, -7.5068e-01, -1.2154e-01,\n",
      "        -1.3554e-01, -9.9289e-02, -5.9157e-01, -8.4843e-01,  8.5158e-02,\n",
      "         1.0931e-01, -2.3708e-01,  1.3745e-01, -1.8919e-01,  1.4879e-01,\n",
      "        -1.1846e-02, -3.3047e-01, -3.8071e-01,  2.0442e-01, -4.5190e-01,\n",
      "         5.4140e-01,  7.1260e-01,  4.0203e-01,  6.9600e-01, -1.6618e-01,\n",
      "        -3.6846e-01,  2.7397e-01, -2.9767e-01,  8.0366e-01,  1.0167e-01,\n",
      "        -3.1320e-01,  6.9538e-02,  2.7824e-01, -6.2698e-01, -9.7257e-01,\n",
      "         1.0796e+00,  1.2801e+00, -1.5675e-01, -5.7370e-01,  5.5004e-01,\n",
      "        -9.3195e-01, -7.4065e-01,  1.5634e+00,  2.2929e-01, -4.0083e-01,\n",
      "         1.1387e-01,  1.0119e-01, -5.1106e-01,  4.6233e-01,  5.0615e-01,\n",
      "         8.5461e-02,  6.4837e-01, -1.0391e-02,  8.5243e-01, -3.3495e-01,\n",
      "        -1.0086e-01,  1.4977e-01,  1.3738e+00,  3.5643e-01,  8.5093e-01,\n",
      "         4.5772e-01,  7.1463e-02,  9.0143e-01, -3.1054e+00, -6.2390e-02,\n",
      "         2.4557e-01, -9.0379e-01,  1.0698e+00, -2.8256e-01,  4.5875e-01,\n",
      "        -2.6756e-01, -1.0496e+00,  8.9529e-02, -8.2438e-01, -3.2915e-01,\n",
      "         2.2632e-01, -1.0146e-01,  3.1821e-01, -9.5751e-01,  4.6268e-02,\n",
      "         5.3080e-01, -1.0584e-01,  2.1216e-01, -5.3166e-01, -4.5202e-01,\n",
      "        -2.6374e-01,  7.3519e-01,  8.0885e-01,  9.2435e-02, -1.5838e+00,\n",
      "        -7.6622e-03, -7.6072e-01, -4.6069e-01, -1.7571e-01, -6.3324e-01,\n",
      "         1.6675e-01, -6.1954e-01,  1.2447e-01, -3.8308e-01,  3.4882e-01,\n",
      "         1.8884e-01,  7.8266e-01, -2.0701e-01, -2.6525e-01, -4.3901e-01,\n",
      "         1.2527e-02, -1.6901e-01,  7.7643e-01, -1.2108e+00, -3.2181e-02,\n",
      "        -4.6421e-01,  4.2265e-01,  8.7008e-01,  5.6495e-01, -6.8301e-01,\n",
      "         1.6022e-01,  1.2724e-02,  2.7703e-01, -6.6133e-01,  1.8433e-01,\n",
      "         2.5176e-01,  9.2308e-01,  6.7621e-01, -3.3079e-01, -8.2164e-03,\n",
      "        -5.0544e-01, -2.9964e-01,  1.4615e-01, -4.1300e-01, -1.1389e+00,\n",
      "        -1.0987e+00,  1.4046e-01,  9.2848e-01,  3.3818e-02,  3.2289e-01,\n",
      "        -7.3215e-01, -1.2947e+00, -2.0382e-01, -3.3537e-01,  3.8179e-01,\n",
      "         1.4948e-01,  1.4581e-01,  2.4144e-01, -8.4325e-01,  7.2568e-03,\n",
      "         8.1695e-02, -3.0652e-01, -1.9404e-01, -1.1712e-01,  4.1522e-01,\n",
      "        -1.3542e-02, -7.5036e-01, -2.9547e-01,  5.1599e-02, -4.5624e-01,\n",
      "         6.3546e-01, -2.7188e-02, -9.7692e-01,  3.0875e-01, -4.1024e-01,\n",
      "         2.4936e-01,  5.0979e-01, -4.4139e-01,  1.0556e+00,  6.5100e-01,\n",
      "        -3.4747e-01,  2.9809e-01,  2.0215e-02,  4.3997e-02, -8.5491e-02,\n",
      "        -4.3777e-02, -6.1756e-01,  6.7055e-01,  3.7928e-01, -1.1001e+00,\n",
      "         5.6407e-01, -9.0973e-01, -6.3911e-01,  9.2289e-01, -4.8782e-02,\n",
      "        -4.0760e-01, -1.4736e-01, -1.5852e-01, -6.7442e-01,  7.9415e-01,\n",
      "        -9.4159e-01, -3.6416e-01,  1.3567e+00,  9.3389e-01, -6.1190e-01,\n",
      "         8.8688e-01,  3.1045e-01, -4.1037e-01,  1.2524e+00, -5.5396e-02,\n",
      "        -6.5674e-01,  6.4263e-01,  1.0617e+00, -1.1276e-01, -1.0059e+00,\n",
      "        -2.7733e-01,  3.2379e-01,  7.0145e-02, -3.8525e-02, -4.6881e-01,\n",
      "        -1.6684e-01, -7.0630e-02, -1.0662e-01,  5.8797e-01, -5.4268e-01,\n",
      "         5.6496e-01,  1.1049e-01, -1.1088e-01, -2.0846e-01,  7.2583e-03,\n",
      "        -2.5405e-01,  1.5225e-01,  4.8876e-01,  8.0388e-02,  1.3387e+00,\n",
      "        -2.0812e-01, -9.0839e-02, -1.5149e-01,  8.1196e-01, -1.0182e+00,\n",
      "         1.6496e+00,  2.3715e-01, -3.9718e-01,  4.9364e-01, -2.7436e-01,\n",
      "        -1.0989e-01, -1.2420e-01, -7.4901e-02, -2.1723e-02, -3.6800e-01,\n",
      "        -6.5048e-02,  6.5383e-01, -4.0025e-01,  6.3440e-01, -2.1885e-01,\n",
      "         9.6605e-01,  1.8174e-01,  5.2740e-01, -7.7411e-02,  2.0434e-01,\n",
      "        -1.3501e-01, -4.2370e-02, -2.8582e-01, -4.4284e-01, -9.1037e-01,\n",
      "        -5.3322e-02, -1.0288e+00, -3.0284e-01, -4.2924e-01,  1.6548e-01,\n",
      "         9.0076e-02, -1.3278e-01, -6.3407e-02, -8.1559e-01,  3.0958e-01,\n",
      "        -6.2180e-02, -1.3305e-01,  1.4593e+00, -3.1301e-01,  4.5945e-01,\n",
      "        -2.1783e-02,  7.3976e-02,  4.4340e-03, -6.7005e-01,  3.5766e-01,\n",
      "        -1.2462e-01, -6.7203e-01, -1.2297e-01, -4.8432e-01, -9.6883e-01,\n",
      "        -1.2338e+00,  4.1318e-01,  1.2094e-01, -3.6419e-01,  3.5168e-01,\n",
      "        -3.5291e-02, -5.3395e-01,  4.8317e-01, -9.7757e-01, -6.5496e-01,\n",
      "         3.2511e-01,  4.7423e-01, -6.1069e-01, -1.7506e-01,  2.0594e-01,\n",
      "         6.9808e-01, -3.0400e-01, -7.4444e-02, -1.8223e-02, -5.5611e-01,\n",
      "        -3.2820e-01,  8.4455e-02, -3.7117e-01,  2.8246e-01,  2.4689e-01,\n",
      "        -2.6178e-01,  1.0439e+00, -8.0282e-01, -1.3620e-01,  3.0074e-01,\n",
      "         3.3205e-01, -7.1852e-02,  1.6091e-01,  1.4394e-01, -6.6894e-01,\n",
      "         3.9225e-01, -1.0182e+00,  2.8931e-01,  2.1167e-01, -2.5143e-01,\n",
      "        -5.9399e-01,  8.5683e-01,  5.1799e-01,  6.7541e-02, -7.0144e-02,\n",
      "         2.2400e-01,  8.4200e-02,  2.9826e-01, -2.2681e-01, -1.0331e+00,\n",
      "        -5.9030e-01,  8.9229e-04,  2.6713e-01, -4.5480e-01, -1.6604e-01,\n",
      "        -5.0054e-03,  6.8639e-01, -8.0461e-01,  8.5359e-01, -5.8744e-01,\n",
      "        -6.3138e-01,  6.8484e-02,  1.5959e-01,  5.8067e-01, -8.3649e-01,\n",
      "        -1.7480e-01,  1.3686e+00,  1.0638e-01, -4.0431e-01, -1.1641e-01,\n",
      "         6.1518e-02, -4.2982e-01, -3.7390e-01,  2.8196e-01, -1.6232e-01,\n",
      "        -2.7618e-01, -2.0384e-01, -4.5251e-01,  2.7056e-01,  4.2295e-01,\n",
      "        -3.8367e-02,  4.3374e-01, -7.4224e-01,  7.3100e-01,  2.2022e-01,\n",
      "         2.9080e-01,  4.4427e-01,  6.4234e-01, -2.7999e-01, -1.0277e-02,\n",
      "         7.9768e-01,  3.3511e-01, -6.4430e-02,  4.6974e-01, -2.5335e-01,\n",
      "        -1.7477e-01,  1.7288e-01,  1.1310e-01,  9.7823e-01, -3.5221e-01,\n",
      "         2.3994e-01,  7.9554e-01,  7.2751e-02, -2.9242e-01,  2.5442e-01,\n",
      "         2.6190e-01, -2.9260e-01,  1.8070e-01,  3.0990e-01, -1.8248e-01,\n",
      "        -2.1971e-02, -3.8165e-01,  7.8243e-01,  1.3562e+00, -9.5394e-01,\n",
      "        -1.3115e-01, -2.9392e-01,  2.1952e-01,  2.0582e-01,  6.3538e-01,\n",
      "        -1.0011e+00,  2.6028e-01, -6.9832e-01, -7.0744e-02, -1.0956e+00,\n",
      "         3.1616e-02,  6.9775e-01, -1.3652e+00,  2.6881e-01,  1.7830e-01,\n",
      "         2.8332e-01,  4.6938e-01,  9.0561e-01, -4.7649e-01, -5.4737e-01,\n",
      "         3.3513e-01,  4.4187e-01,  2.9014e-01, -2.4494e-01, -4.6879e-01,\n",
      "         2.6760e-01, -8.0275e-01,  5.1305e-01,  7.5538e-01,  2.1843e-01,\n",
      "         1.3672e-01, -2.8048e-01,  9.8010e-01,  7.0673e-01, -1.5129e-01,\n",
      "         3.4314e-01, -5.1270e-01, -5.6500e-02,  1.9426e-01, -8.3298e-01,\n",
      "        -1.4505e+00, -1.3437e+00, -2.0580e-01,  4.3158e-01,  1.4004e-01,\n",
      "         1.0291e+00,  6.7747e-01,  3.7553e-01, -4.3608e-01, -6.9905e-01,\n",
      "         1.0420e-01, -8.3959e-01,  2.2138e-01, -3.2395e-02,  2.6463e-01,\n",
      "        -7.6226e-01,  8.8579e-03, -1.7413e-01, -5.9316e-01,  9.2157e-02,\n",
      "         2.3155e-01, -3.4696e-01, -8.3987e-01, -1.0865e-01,  1.1946e-01,\n",
      "        -1.7265e-02, -3.0219e-01,  4.3935e-01, -4.8408e-01,  7.3133e-01,\n",
      "         1.1138e+00,  8.3402e-01,  9.4302e-01,  6.0884e-01, -4.1277e-01,\n",
      "        -5.4004e-01,  8.1134e-02, -4.8541e-01, -3.3737e-01, -3.4983e-01,\n",
      "        -5.7199e-01, -1.8867e-01,  3.1290e-01,  9.1288e-01,  3.0120e-01,\n",
      "        -5.3301e-01,  1.0208e+00, -1.2234e+00, -3.9243e-01,  1.2069e+00,\n",
      "        -1.8044e-01,  3.8067e-02, -5.9628e-01,  2.8066e-01, -1.3306e-01,\n",
      "        -8.4866e-01,  5.1553e-01, -6.8813e-01, -1.0969e+00, -2.9240e-01,\n",
      "         6.0147e-01, -1.3104e+00, -1.0964e-01, -4.7934e-01, -4.4010e-01,\n",
      "         8.0588e-01,  3.8068e-01,  2.4727e-01, -5.7231e-01, -3.5995e-01,\n",
      "        -5.2130e-02, -3.4017e-02, -7.4374e-01,  1.6821e-01,  8.1411e-01,\n",
      "         1.0570e+00,  4.2416e-01, -2.6701e-02,  2.0358e-01, -6.4078e-01,\n",
      "        -1.0408e+00,  3.1806e-01,  3.0349e-01,  7.9781e-01, -1.4911e-01,\n",
      "        -9.1791e-02,  1.2590e-01, -5.4748e-01, -6.0396e-01,  1.1365e-01,\n",
      "        -8.8036e-01, -3.3834e-01, -1.7813e-01])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Embedding for 'bank': {emb1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31397b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 5.9083e-01,  4.7655e-02,  6.9020e-02,  6.6070e-02,  1.1558e+00,\n",
      "        -3.4510e-01, -1.8744e-01,  1.0186e+00, -3.6762e-02,  3.6435e-01,\n",
      "         3.3772e-01, -9.0620e-01, -2.0067e-01,  6.1692e-02, -7.5448e-01,\n",
      "        -4.1178e-01,  1.9047e-01,  3.9089e-01,  1.2114e+00,  5.5650e-01,\n",
      "        -3.6517e-01,  1.7254e-01,  6.7308e-01,  1.0322e-02,  2.5009e-01,\n",
      "         5.2667e-01,  6.8564e-01,  7.1187e-01, -4.8951e-01, -4.5971e-01,\n",
      "         4.9835e-01,  5.3231e-01,  5.1483e-01,  3.3559e-01,  3.8936e-01,\n",
      "        -5.0638e-02, -6.9605e-02,  1.3594e-01, -8.7222e-01, -3.8655e-02,\n",
      "        -3.8724e-01, -1.0177e+00, -3.1066e-01,  3.9200e-01, -6.5535e-01,\n",
      "        -6.6317e-01,  5.4388e-01,  4.4756e-01, -6.8695e-01, -6.6272e-01,\n",
      "        -1.4000e-01,  9.2609e-01,  3.4183e-01, -6.4659e-01,  4.6637e-01,\n",
      "         5.6735e-01, -8.8206e-01, -4.6287e-01, -8.3607e-01, -2.6055e-01,\n",
      "         7.6207e-01,  2.2162e-01,  3.1346e-01, -5.7102e-01,  3.8509e-01,\n",
      "        -2.2441e-01,  4.3680e-01, -3.4997e-02, -3.3293e-01, -2.9453e-01,\n",
      "        -2.8272e-02,  1.8603e+00, -8.6660e-01, -9.4056e-01, -6.4794e-01,\n",
      "         4.9291e-01, -6.8156e-01,  7.3014e-01, -5.2581e-02, -3.5091e-02,\n",
      "        -5.0062e-01, -1.0940e+00, -2.4988e-01,  2.8273e-01,  6.2855e-01,\n",
      "        -5.4212e-01, -5.4913e-02,  7.5467e-02, -4.4659e-01,  1.1288e+00,\n",
      "        -1.3230e-01,  6.8484e-02, -7.2958e-01, -7.5778e-03, -1.1255e+00,\n",
      "         5.8336e-02,  6.5023e-02,  1.4187e-01, -2.3116e-01,  8.7595e-01,\n",
      "         4.6817e-01, -1.2339e+00, -1.7796e-01, -3.4834e-02,  2.4154e-02,\n",
      "         1.7831e-01, -9.6299e-01, -1.5516e-01, -1.6711e-02,  2.2522e-01,\n",
      "        -1.4302e-01, -1.1318e+00,  5.4707e-01, -8.1421e-01, -2.5510e-01,\n",
      "        -6.8234e-01, -1.8450e-01, -6.1601e-01, -5.8024e-01, -1.5322e-01,\n",
      "         3.0842e-01,  9.9335e-01,  7.7976e-01,  1.3671e+00,  6.4812e-01,\n",
      "         2.2879e-01, -1.1155e-01,  6.4201e-01, -4.5081e-01, -1.7002e-02,\n",
      "         2.5352e-01,  2.9591e-01, -6.3374e-03, -2.0306e-01,  2.6507e-01,\n",
      "        -6.5100e-01, -6.3040e-01, -6.3784e-01, -7.0369e-01,  4.8712e-01,\n",
      "         7.0626e-01,  1.2207e+00,  4.1994e-01,  1.6146e+00, -2.5654e-01,\n",
      "         7.7852e-02, -2.6324e-01, -7.1401e-01, -5.0181e-01, -3.3300e-01,\n",
      "        -2.0823e-01, -2.5643e-01, -1.8140e-01, -2.8494e-01,  2.9178e-02,\n",
      "         1.3471e-01, -2.1502e-01, -1.4621e-01, -7.9138e-01, -8.6132e-02,\n",
      "         2.1248e-01, -1.9951e-03, -4.4984e-01, -1.2763e-02, -4.4931e-01,\n",
      "        -6.1442e-01,  2.6514e-01,  5.0283e-01, -5.4040e-03,  3.3740e-01,\n",
      "        -5.2714e-01,  1.2778e-01,  1.2248e+00, -2.7514e-01,  9.1607e-01,\n",
      "         7.4500e-02, -6.4428e-01, -4.9029e-01,  4.9136e-01,  5.6640e-01,\n",
      "         4.2650e-04,  9.1345e-01,  2.3289e-01,  6.9004e-01,  1.0336e+00,\n",
      "         4.9661e-01,  7.0737e-01,  3.1478e-01,  1.7433e-01, -4.7498e-01,\n",
      "        -3.0776e-01, -3.8201e-01, -5.2677e-01,  1.5253e-01, -1.7328e-01,\n",
      "        -7.7653e-02, -2.9361e-01, -3.4195e-01, -8.1604e-01, -1.5507e-01,\n",
      "         2.4131e-01, -1.4459e+00,  2.9502e-01,  1.4715e-01, -5.2043e-01,\n",
      "         1.6833e-01,  4.1460e-01,  5.7837e-01,  1.4013e+00, -2.6065e-01,\n",
      "        -4.3778e-01,  5.7740e-01, -6.8206e-01, -3.4075e-02, -5.8731e-01,\n",
      "         6.9206e-01,  4.7592e-02, -9.3869e-01, -2.7211e-02,  1.0423e-01,\n",
      "         3.7428e-01, -1.6154e-01,  3.0016e-01,  6.3574e-01,  2.4234e-01,\n",
      "         4.0031e-01,  3.3862e-01, -3.0369e-01,  1.9864e-01, -1.3343e-01,\n",
      "        -1.2180e-02, -6.5054e-02,  7.9243e-01, -9.1182e-02, -1.2524e-01,\n",
      "        -3.2806e-01, -1.2931e+00, -8.8691e-01, -2.4509e-01,  2.1779e-01,\n",
      "        -5.3375e-01, -2.1607e-01, -4.0697e-01, -5.4578e-02,  6.5888e-01,\n",
      "         5.8588e-01, -4.1869e-01, -5.3332e-01,  4.4175e-01, -4.2354e-01,\n",
      "        -4.1679e-02, -7.9774e-01, -3.4264e-01, -7.0120e-01,  8.9608e-01,\n",
      "        -8.5618e-02, -9.2607e-02, -3.0228e-01, -5.7183e-01,  8.9644e-01,\n",
      "         5.7308e-01, -8.0351e-02, -1.9043e-01,  4.1510e-01, -8.1401e-01,\n",
      "        -5.0552e-01, -7.1966e-02,  2.4670e-01,  5.7573e-01,  6.4733e-01,\n",
      "         6.0543e-01,  3.5688e-01, -4.6940e-01,  1.5249e+00,  1.3468e+00,\n",
      "        -7.1612e-01,  7.5385e-02,  3.2999e-01,  2.9516e-01,  2.4734e-01,\n",
      "         2.0620e-01,  9.5995e-01, -2.0277e-01, -9.0242e-01,  1.4512e-01,\n",
      "        -6.1615e-01, -1.4146e-01,  2.5665e+00, -5.2492e-01, -7.0542e-01,\n",
      "        -1.0714e-01,  2.2645e-01, -6.1502e-01, -9.4145e-01,  2.6126e-01,\n",
      "         6.5545e-01, -2.8094e-02,  7.8374e-01,  1.0267e+00,  1.1303e-01,\n",
      "         6.2911e-01,  1.2426e-01,  1.0321e+00, -2.2796e-01, -5.1783e-01,\n",
      "        -8.9153e-02, -1.9213e-01, -4.9125e-01, -2.7271e+00,  8.8611e-01,\n",
      "        -2.1109e-01, -2.7877e-01,  6.9566e-01,  2.3747e-01,  2.1770e-01,\n",
      "        -3.1854e-01, -1.1117e+00, -2.4712e-01, -1.3511e+00, -7.3452e-01,\n",
      "         1.0030e+00,  2.1161e-01, -5.9684e-02, -3.4016e-01,  9.4741e-01,\n",
      "         2.2959e-01, -1.6887e-01,  7.5349e-01, -2.7347e-01, -6.8206e-01,\n",
      "        -6.0097e-01,  5.0991e-01,  6.3078e-01,  9.1384e-01, -4.8742e-01,\n",
      "         4.0602e-01,  2.1541e-01,  6.8560e-01, -4.1142e-01, -2.8003e-01,\n",
      "         4.3857e-01, -1.7489e-01,  2.7008e-01, -8.3542e-02, -6.7190e-01,\n",
      "        -1.9008e-02,  7.8170e-01, -6.6149e-01, -5.6296e-03,  1.2440e-01,\n",
      "         2.4686e-01,  5.1103e-01,  1.5455e+00, -5.8259e-01,  3.1076e-01,\n",
      "         8.1799e-01, -5.1521e-01,  1.2220e+00,  6.2531e-01,  3.0136e-01,\n",
      "        -3.6011e-01, -3.4546e-01,  1.9255e-01,  4.8114e-01,  5.3818e-01,\n",
      "         1.0674e+00,  6.7140e-01,  6.0574e-02, -6.0635e-01, -4.8154e-01,\n",
      "         1.6282e-01, -3.0661e-01, -3.5288e-01, -6.2130e-01, -1.1113e+00,\n",
      "        -8.6909e-01,  3.7891e-01,  4.5647e-02, -6.7922e-01, -8.9752e-02,\n",
      "        -2.3158e-01, -1.1183e+00, -4.8769e-01, -3.8892e-01,  7.8518e-01,\n",
      "         3.5081e-01, -2.6333e-02,  1.7609e-01,  9.2206e-01, -3.2199e-01,\n",
      "        -8.0479e-02, -6.9925e-01, -7.8616e-02, -2.5269e-01, -2.2289e-01,\n",
      "        -4.1865e-01, -9.6110e-01, -6.8011e-01,  3.1427e-01,  8.1159e-01,\n",
      "         5.5249e-01, -9.5325e-01,  9.5835e-02,  3.7091e-01, -3.6422e-01,\n",
      "         2.2680e-01, -2.0402e-01, -4.1948e-01,  2.3941e-01,  1.5955e+00,\n",
      "         3.0988e-01, -1.2516e-01, -1.0930e-01,  2.3178e-01, -1.4863e-01,\n",
      "        -8.0461e-02, -1.3267e+00,  8.5930e-01,  1.0073e+00, -1.2401e+00,\n",
      "         1.3450e+00, -1.3165e+00,  3.3113e-01,  5.4879e-01,  7.8845e-01,\n",
      "        -9.6004e-01,  3.7149e-01, -1.8875e-01, -5.4388e-01,  6.8293e-02,\n",
      "        -2.3457e-01, -8.8081e-01, -9.9822e-01, -4.4250e-01,  3.9429e-01,\n",
      "        -2.1331e-01, -6.3600e-01, -4.2468e-01,  6.4412e-01,  7.8866e-02,\n",
      "        -2.9851e-01,  1.0810e-01,  4.6942e-01,  5.0546e-01,  3.0509e-01,\n",
      "        -1.7270e-01,  3.9826e-01, -5.1330e-01,  6.9339e-01,  7.1121e-01,\n",
      "        -4.1343e-01,  1.5987e-01, -8.2220e-01, -8.2217e-01, -8.8535e-01,\n",
      "         5.5552e-01,  2.3356e-01,  2.9346e-01, -7.7803e-01, -1.0817e-01,\n",
      "         2.2136e-01,  2.1547e-01,  7.5786e-01,  1.7329e-01,  1.0634e+00,\n",
      "        -2.9618e-01, -5.2239e-01, -7.8182e-01,  7.8857e-01, -2.5563e-01,\n",
      "         8.3838e-01,  3.8779e-01, -1.0144e+00, -1.9915e-01, -9.6480e-01,\n",
      "        -9.0226e-01,  1.0555e-02,  4.9514e-01, -7.5667e-01, -9.7687e-02,\n",
      "         1.8597e-01,  3.8359e-01,  9.6440e-02, -1.2236e-01, -2.2759e-01,\n",
      "         4.1734e-01,  1.4754e-01,  1.3969e-01, -2.0995e-01, -1.7419e-01,\n",
      "        -3.3514e-01, -4.4212e-01,  8.0873e-01,  1.1975e+00,  2.0762e-01,\n",
      "         2.0747e-01, -2.3777e-01, -3.0835e-01, -6.9464e-01,  1.0799e+00,\n",
      "        -2.0183e-01, -7.0624e-02, -4.4111e-01, -1.3065e+00,  2.3948e-01,\n",
      "         5.2835e-02, -7.5688e-01,  8.3810e-01, -6.1476e-01,  4.8924e-01,\n",
      "        -5.1408e-01,  2.9152e-01,  3.9813e-01,  7.2805e-01,  1.5185e-01,\n",
      "        -1.3260e-01, -8.8718e-01,  8.0893e-01,  7.0488e-02, -6.9592e-01,\n",
      "        -1.2203e+00, -3.3848e-01, -1.8721e-01, -9.9819e-01,  5.5896e-01,\n",
      "        -3.4997e-01,  1.3967e-01,  3.9983e-01, -7.3909e-01, -5.1979e-01,\n",
      "         1.4492e-01,  2.2301e-01, -1.5791e+00, -2.8448e-02, -2.6282e-01,\n",
      "         7.6197e-01, -5.4917e-01,  9.2626e-01, -7.7698e-01, -1.0949e-01,\n",
      "         4.3842e-01,  1.5427e-01, -1.8742e-01,  1.8502e-01, -3.6896e-01,\n",
      "        -1.4468e+00,  2.2779e-01, -2.8349e-01, -7.8731e-01, -3.0048e-01,\n",
      "         6.1269e-02, -3.2134e-01, -3.1093e-01,  2.8511e-01,  3.5686e-01,\n",
      "         1.1596e+00, -6.9769e-02,  8.8146e-01,  8.8214e-01, -1.4125e-01,\n",
      "         2.3968e-01,  6.0288e-02, -4.8604e-01,  2.4053e-01, -3.9960e-01,\n",
      "        -2.8525e-01, -4.4231e-02,  2.3771e-01,  4.1832e-01, -9.2841e-01,\n",
      "        -7.3758e-01,  2.1938e-01,  5.1968e-01,  2.2034e-01,  1.6998e-01,\n",
      "         2.3349e-01, -1.2804e-01, -5.7595e-01,  4.3169e-02, -1.1296e+00,\n",
      "        -5.4326e-02, -4.6951e-01, -8.1570e-02, -6.7503e-02, -1.6685e+00,\n",
      "        -8.8122e-01,  2.2645e-02, -1.1207e-01, -6.7200e-01,  3.0391e-01,\n",
      "        -6.9109e-02,  6.1570e-01, -7.7059e-01, -1.7341e-01, -1.1823e+00,\n",
      "         1.8669e-02, -3.2475e-01, -5.1312e-01, -3.8355e-02,  8.3702e-01,\n",
      "         1.8866e-01, -2.7959e-01, -7.8892e-02,  5.9145e-01,  6.6128e-01,\n",
      "        -1.2992e-01, -1.0697e-01,  3.7401e-01,  4.2451e-01, -6.5458e-01,\n",
      "         3.2824e-01,  3.2522e-01,  5.2432e-01,  2.9321e-01, -2.8460e-01,\n",
      "        -4.1767e-01,  4.8767e-01,  3.5440e-01, -9.5295e-01, -1.2925e+00,\n",
      "         7.7931e-01,  2.7414e-01, -1.5682e+00,  6.6529e-01, -3.4406e-02,\n",
      "        -3.0151e-01, -6.0089e-01,  7.9747e-01, -2.0948e-01,  1.7097e-01,\n",
      "         2.7802e-01,  4.7869e-02,  8.4447e-02,  3.9938e-01, -4.1996e-01,\n",
      "        -2.9065e-01,  2.4690e-01, -1.7017e-01,  1.8758e-02,  6.8497e-01,\n",
      "        -3.1959e-01,  3.4732e-01,  3.4573e-03,  2.0509e-01, -4.7089e-01,\n",
      "        -3.8642e-01,  2.7582e-01, -2.2207e-01,  4.3039e-01, -3.9295e-01,\n",
      "        -3.9897e-01,  1.1314e+00,  8.4164e-02, -3.1155e-01,  5.5203e-03,\n",
      "        -1.0715e-01,  7.3143e-01,  4.7100e-01, -6.3868e-02,  5.0433e-01,\n",
      "        -7.7099e-01, -9.2156e-01,  3.4465e-01,  6.0157e-01,  8.6836e-01,\n",
      "         6.2705e-02, -6.3766e-01,  1.0335e+00,  3.5776e-01,  5.4406e-01,\n",
      "        -9.1799e-02, -3.6680e-01, -1.0495e-01,  5.3527e-02,  1.1835e-01,\n",
      "        -6.3124e-01,  1.9718e-01,  2.9135e-01, -2.5667e-01, -3.2574e-01,\n",
      "         1.0778e+00,  3.0837e-01, -1.7650e-01, -6.2180e-01, -8.0287e-01,\n",
      "         1.1232e-01,  2.7280e-01, -5.9392e-01,  3.2387e-01, -6.8884e-01,\n",
      "        -6.4014e-01, -6.6123e-01, -1.8981e-01, -1.0643e+00,  7.8885e-01,\n",
      "        -4.9026e-01, -3.0956e-01, -6.8345e-01,  4.2334e-01,  3.9608e-01,\n",
      "        -5.8694e-01,  5.0947e-01,  4.3624e-01, -8.3276e-01,  4.7990e-01,\n",
      "        -3.6189e-01,  7.0698e-01,  2.5194e-01,  2.2205e-01, -3.9078e-01,\n",
      "        -1.6053e-01, -6.7127e-02,  3.5574e-01, -5.9428e-02,  8.8516e-01,\n",
      "        -3.1861e-01, -6.2116e-01,  3.8903e-01,  8.6523e-01,  7.9504e-01,\n",
      "        -3.9288e-01,  1.4250e+00, -6.0538e-01, -6.4195e-01,  3.7888e-01,\n",
      "         1.1104e-01,  1.4592e-01,  8.6856e-02, -2.0152e-01,  4.4047e-01,\n",
      "        -2.9623e-01, -9.6719e-03, -8.7345e-01, -3.9124e-01, -1.4347e-01,\n",
      "         1.6544e-01,  2.7606e-01,  3.2272e-01, -1.1424e+00, -3.8812e-01,\n",
      "         8.5549e-02,  1.6076e+00, -1.1039e-01,  1.5194e-02,  1.5967e-01,\n",
      "        -1.0609e-01, -3.8533e-01, -1.9516e-01,  1.2367e+00,  1.6773e-01,\n",
      "         4.2613e-01,  5.2506e-01,  6.8470e-01, -5.3825e-03, -7.3080e-01,\n",
      "        -4.4811e-01, -8.1616e-01, -2.9708e-01, -6.2886e-01, -3.0876e-01,\n",
      "        -5.0861e-01, -3.4938e-01,  8.7539e-03, -2.5259e-01, -4.7566e-01,\n",
      "        -7.0864e-01, -3.8015e-01, -5.4529e-02])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding for 'bank': {emb2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452381f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89233861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do they do it? distinguish the context of the words in the sentence\n",
    "# its due to a lot of things\n",
    "# training on large datasets\n",
    "# the architecture of the model\n",
    "# the attention mechanism\n",
    "# the way the model is trained\n",
    "\n",
    "\n",
    "# instead of tokenizing and preprocessing to remove noise, and stemming; and then counting the word occurrences,\n",
    "# bert tokenizes the text in to token and converts the tokens to embeddings\n",
    "# the embeddings are then passed through the model to get the output\n",
    "# the model is trained on a large corpus of text and can be fine-tuned for specific tasks such as sentiment analysis, text classification, etc.\n",
    "# the model is able to take into account the context of the words in the sentence and provide a more accurate representation of the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7d54a",
   "metadata": {},
   "source": [
    "![alt text](images/bert-gen-emb-full.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573ac9c",
   "metadata": {},
   "source": [
    "![alt text](images/bert-gen-emb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915243fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language models geenrate contextual embeddings for the words in the sentence using the attention mechanism\n",
    "# which tries to understand what impact each token in the sentence has on the other tokens\n",
    "# this is done by calculating the attention scores for each token in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e81b26",
   "metadata": {},
   "source": [
    "![alt text](images/attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdff885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# innovation - transformers architecture\n",
    "# can scale to large datasets, train faster\n",
    "# can be used for transfer learning\n",
    "\n",
    "# its build in two parts:\n",
    "# 1. pre-training: learn the general patterns of language from large datasets first, grammar, syntax, semantics\n",
    "# 2. fine-tuning: pre-train on large datasets like Wikipedia, Common Crawl, etc.\n",
    "# learn the general patterns of language from large datasets first, grammar, syntax, semantics\n",
    "# pre-train on large datasets like Wikipedia, Common Crawl, etc.\n",
    "# pre-trained models can be used for various tasks like text classification, named entity recognition, etc\n",
    "# pre-trained models can be fine-tuned on specific tasks with smaller datasets\n",
    "# BERT, GPT, RoBERTa, etc. are examples of pre-trained models\n",
    "# pre-trained models are trained on large datasets, learn the general patterns of language\n",
    "# and can be used for various tasks like text classification, named entity recognition, etc.\n",
    "# pre-trained models can be used for transfer learning, where the model is trained on a large dataset\n",
    "# to learn the general patterns of language, and then fine-tuned on specific tasks with smaller datasets\n",
    "# pre-trained models can be used for various tasks like text classification, named entity recognition\n",
    "# text generation, etc.\n",
    "# pre-trained models can be used for transfer learning, where the model is trained on a large\n",
    "# and then fine-tune on specific tasks\n",
    "# BERT - Bidirectional Encoder Representations from Transformers\n",
    "# GPT - Generative Pre-trained Transformer\n",
    "\n",
    "# langauge modelling task \n",
    "# predict the next word in a sentence\n",
    "# masked language modelling task\n",
    "# predict the masked word in a sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b75f12",
   "metadata": {},
   "source": [
    "<img src=\"images/bert-transfer-learning.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did transformers achieve this?\n",
    "# through attention mechanism\n",
    "# earlier models used RNNs, LSTMs, GRUs, etc.\n",
    "# these models processed the input sequence one token at a time, which made them slow and difficult\n",
    "# to parallelize\n",
    "# transformers process the entire input sequence at once, which makes them faster and easier to parallelize\n",
    "# transformers use self-attention mechanism to process the input sequence\n",
    "# self-attention mechanism allows the model to focus on different parts of the input sequence\n",
    "# and learn the relationships between the tokens in the sequence\n",
    "# self-attention mechanism allows the model to learn the relationships between the tokens in the sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cde9183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83d487",
   "metadata": {},
   "source": [
    "# there are two types of language modelling tasks\n",
    "# 1. Causal LM: next word prediction task: predict the next word in a sentence\n",
    "# 2. Masked LM: masked language modelling task: predict the masked word in a sentence\n",
    "\n",
    "\n",
    "## Causal LM\n",
    "\n",
    "<img src=\"images/clm.png\">\n",
    "\n",
    "## Masked LM\n",
    "\n",
    "<img src=\"images/mlm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language models are powerful tools for natural language processing tasks\n",
    "# trained on large datasets, learn the general patterns of language\n",
    "# can be fine tuned on specific tasks such as sentiment analysis, text classification, etc.\n",
    "# reason why they are so powerful \n",
    "\n",
    "# and current wave of GenAI is due to the advancements in language models\n",
    "# with more scaling, better architectures, and more data\n",
    "# language models are able to generate human-like text, understand the context of the text, and\n",
    "# perform various natural language processing tasks with high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c77cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4c2e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets build a sentiment classifer with BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1bbaf",
   "metadata": {},
   "source": [
    "![alt](images/llm-sentiments-classifier.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6e13d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73303a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   999,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenizer(\"Hello, my dog is cute!\", return_tensors=\"pt\")\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5512a9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'hello', ',', 'my', 'dog', 'is', 'cute', '!', '[SEP]']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(token_id) for token_id in tokenized_text[\"input_ids\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f49b8245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (800,), Test shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    df[\"text\"].values, df[\"label\"].values, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Train shape: {train_x.shape}, Test shape: {test_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bdb17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 800/800 [00:00<00:00, 6538.62 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 9197.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# using datasets library to create datasets for training and testing\n",
    "import datasets\n",
    "train_dataset = datasets.Dataset.from_dict({\"text\": train_x, \"label\": train_y})\n",
    "test_dataset = datasets.Dataset.from_dict({\"text\": test_x, \"label\": test_y})\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=16),\n",
    "    batched=True,\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=16),\n",
    "    batched=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d9817",
   "metadata": {},
   "source": [
    "![alt text](images/bert-cls.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5661c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "cls_model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40da245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e362da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.5087944865226746}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5132016539573669}]\n"
     ]
    }
   ],
   "source": [
    "pipe = transformers.pipeline(\"sentiment-analysis\", model=cls_model, tokenizer=tokenizer,)\n",
    "print(pipe(\"I love this!\"))\n",
    "print(pipe(\"I hate this!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e6c654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The worst was the salmon sashimi.', 'label': 0, 'input_ids': [101, 1996, 5409, 2001, 1996, 11840, 24511, 27605, 1012, 102, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39fb58ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the worst was the salmon sashimi.\n",
      "['[CLS]', 'the', 'worst', 'was', 'the', 'salmon', 'sash', '##imi', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=True))\n",
    "print([tokenizer.decode(id) for id in train_dataset[0][\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5bd5b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashishu007/Documents/side-projects/nlp-intro/.venv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695208</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694541</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\", max_length=16)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5,\n",
    "    max_steps=10,\n",
    ")\n",
    "# play with these parameters to see how they affect the training\n",
    "# e.g., change max_steps to 1000, increase batch_size, etc.\n",
    "# learn about these parameters here: https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
    "trainer = Trainer(\n",
    "    model=cls_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).mean()},\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(\"./model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2ec96b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/vocab.txt',\n",
       " './model/added_tokens.json',\n",
       " './model/tokenizer.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a69ea7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.5220035314559937}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.52321457862854}]\n"
     ]
    }
   ],
   "source": [
    "# use transfoermers pipeline to test the model\n",
    "pipe = transformers.pipeline(\"sentiment-analysis\", model=\"./model\", tokenizer=\"./model\",)\n",
    "print(pipe(\"I love using Hugging Face transformers!\"))\n",
    "print(pipe(\"I hate using Hugging Face transformers!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6eb80b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.5180331468582153}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5273443460464478}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"I love this!\"))\n",
    "print(pipe(\"I hate this!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ba12050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love using Hugging Face transformers!\n",
      "Predicted class ID: 0\n",
      "Predicted class: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "text = \"I love using Hugging Face transformers!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = cls_model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "predicted_class = id2label[predicted_class_id]\n",
    "print(f\"Text: {text}\\nPredicted class ID: {predicted_class_id}\\nPredicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8eb1e7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[0.5220, 0.4780]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2455, 0.1574]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the logits to probabilities\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "print(f\"Probabilities: {probabilities}\")\n",
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a720c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
